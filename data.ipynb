{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "# If pymc3\n",
    "\"\"\"\n",
    "# import pymc3 as pm\n",
    "# from theano import tensor as tt\n",
    "\"\"\"\n",
    "# If pymc4\n",
    "\"\"\"\n",
    "import pymc as pm\n",
    "import pytensor.tensor as tt\n",
    "\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader import *\n",
    "sys.path.append('../')\n",
    "\n",
    "from os import path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(1116)\n",
    "\n",
    "def Bayesian_IDM_pool(vt, s, dv, label_v):\n",
    "    print(\"training size:\", label_v.shape[0])\n",
    "    dt = 1 / 30 * FREQ\n",
    "\n",
    "    model = pm.Model()\n",
    "\n",
    "    D = 5\n",
    "    \n",
    "    with model:\n",
    "        def IDM_v(VMAX, DSAFE, TSAFE, AMAX, AMIN, DELTA, s, vt, dv):\n",
    "            sn = DSAFE + vt * TSAFE + vt * dv / (2 * np.sqrt(AMAX * AMIN))\n",
    "            a = AMAX * (1 - (vt / VMAX) ** DELTA - (sn / s) ** 2)\n",
    "            return vt + a * dt\n",
    "        mu_prior = pm.floatX(np.array([0, 0,0,0,0]))\n",
    "        parameters_normalized = pm.MvNormal('mu_normalized', mu_prior, chol=np.eye(D))\n",
    "        \n",
    "        log_parameters = pm.Deterministic('log_mu', parameters_normalized*np.array([.3, 1., 1., .01, .5])\n",
    "                                      +np.array([2., 0.69, 0.47, -.3, -.51]))\n",
    "        parameters = pm.Deterministic('mu', tt.exp(log_parameters))\n",
    "        \n",
    "        DELTA = 4\n",
    "        \n",
    "        log_s_v = pm.Uniform('log_s_v', lower=-5.0, upper=-1.0)\n",
    "        s_v = pm.Deterministic('s_v', tt.exp(log_s_v))\n",
    "        \n",
    "        v_obs = pm.Normal('obs', mu=IDM_v(parameters[0], parameters[1], parameters[2], parameters[3],\n",
    "                                          parameters[4], DELTA, s, vt, dv), sigma=s_v, observed=label_v)\n",
    "\n",
    "        tr = pm.sample(5000, tune=20000, random_seed=16, init='jitter+adapt_diag_grad', chains=2,\n",
    "                       cores=8, discard_tuned_samples=True, return_inferencedata=True, target_accept=0.95)\n",
    "    return tr, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5357\r"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for file in os.listdir('Alafaya'):\n",
    "    if file.endswith('.csv'):\n",
    "        data = data.append(pd.read_csv('Alafaya/University@Alafaya-01.csv'))\n",
    "data = data.reset_index()\n",
    "data = data[data['frameNum'].apply(lambda x: x % FREQ == 0)]\n",
    "# pts = gpd.GeoDataFrame(geometry=data[['carCenterLon', 'carCenterLat']].apply(lambda x: Point(x), axis=1)).set_crs({'init': 'epsg:4326'}).to_crs({'init': 'epsg:3857'})\n",
    "# data[['x', 'y']] = pts.apply(lambda x: [x.geometry.x, x.geometry.y], axis=1)\n",
    "data = extract_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = pd.read_csv('results.csv')\n",
    "\n",
    "new_data = []\n",
    "ratio = 0.44704 # convert from mph to m/s\n",
    "for index, group in data.groupby(['carId']):\n",
    "    group = group.sort_values(by=['frameNum'])\n",
    "    group['next_speed'] = group['speed'].shift(-1) * ratio\n",
    "    group['speed'] = group['speed'] * ratio\n",
    "    group['relative_speed'] = group['relative_speed'] * ratio\n",
    "    new_data.append(group)\n",
    "new_data = pd.concat(new_data)\n",
    "new_data.dropna(inplace=True)\n",
    "new_data = new_data[(new_data.speed > 0)]\n",
    "\n",
    "\n",
    "speed = new_data['speed'].values\n",
    "relative_speed = new_data['relative_speed'].values\n",
    "distance = new_data['distance'].values \n",
    "next_speed = new_data['next_speed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = False\n",
    "new_data['relative_speed'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, model = Bayesian_IDM_pool(speed, distance, relative_speed, next_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(tr, var_names=[\"mu\",\"log_mu\",\"s_v\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tr.posterior.mu.to_dataframe()\n",
    "results = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    col = df.iloc[df.index.get_level_values('mu_dim_0') == i, 0]\n",
    "    results['mu_{}'.format(i)] = list(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.cov()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e0bf609c73c312199017514eaf9c15da6dc39ab8bba0e68ea5878a1b5a9c47e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
